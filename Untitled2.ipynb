{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csense.benchmark import cqa\n",
    "from PyDictionary import PyDictionary\n",
    "import spacy\n",
    "dictionary=PyDictionary()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cqa.getDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answerKey': 'C',\n",
       " 'id': 'cf309189e09e1699b4205e0fae88aa45',\n",
       " 'question': {'question_concept': 'table',\n",
       "  'choices': [{'label': 'A', 'text': 'kitchen'},\n",
       "   {'label': 'B', 'text': 'poker'},\n",
       "   {'label': 'C', 'text': 'meeting'},\n",
       "   {'label': 'D', 'text': 'livingroom'},\n",
       "   {'label': 'E', 'text': 'internet cafe'}],\n",
       "  'stem': 'WHen do people sit around a table together at work?'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = dataset[6859]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(question['question']['stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3973924648393389\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for question in dataset:\n",
    "    doc = nlp(question['question']['stem'])\n",
    "    for token in doc:\n",
    "        if token.text == 'what':\n",
    "            cnt = cnt + 1\n",
    "print(cnt/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### noun chunks ###\n",
      "you\n",
      "you\n",
      "rest\n",
      "you\n",
      "what\n",
      "### dependency parse ###\n",
      "If mark legs NOUN []\n",
      "you nsubj legs NOUN []\n",
      "legs nsubj are VERB [If, you]\n",
      "are ROOT are VERB [legs, tired, and, need]\n",
      "tired acomp are VERB []\n",
      "and cc are VERB []\n",
      "you nsubj need VERB []\n",
      "need conj are VERB [you, have, do, ?]\n",
      "to aux have VERB []\n",
      "have xcomp need VERB [to, rest]\n",
      "a det rest NOUN []\n",
      "rest dobj have VERB [a]\n",
      "you nsubj do VERB []\n",
      "should aux do VERB []\n",
      "do ccomp need VERB [you, should, what]\n",
      "what dobj do VERB []\n",
      "? punct need VERB []\n"
     ]
    }
   ],
   "source": [
    "print(\"### noun chunks ###\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.root.text)\n",
    "    \n",
    "print(\"### dependency parse ###\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxiliary'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('AUX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
